{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "virgin-ghost",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:10:34.900793700Z",
     "start_time": "2023-10-17T17:10:34.895922Z"
    }
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "def get_mape(y_predict, y_true):\n",
    "    return (abs(y_predict - y_true) / y_true).mean()\n",
    "\n",
    "def process_rooms_number(x):\n",
    "        \n",
    "    if pd.isna(x):\n",
    "        return 1\n",
    "    \n",
    "    if isinstance(x, int):\n",
    "        return x\n",
    "    \n",
    "    if x.isdigit():\n",
    "        return int(x)\n",
    "    \n",
    "    if x == 'Студия':\n",
    "        return 1\n",
    "    \n",
    "    if x == 'Своб. планировка':\n",
    "        return 1\n",
    "    \n",
    "    if x == '> 9':\n",
    "        return 10\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-bahamas",
   "metadata": {},
   "source": [
    "<h3>Реализуем линейную регрессию</h3>\n",
    "\n",
    "<p>Чаще всего алгоритмы машинного обучения реализуются в виде классов с обязательными методами <code>.fit()</code>, <code>.predict()</code>. </p>\n",
    "\n",
    "<p><code>.fit()</code> – обучить алгоритм на обучающей выборке;</p>\n",
    "\n",
    "<p><code>.predict()</code> – сделать предсказание на тестовых данных.</p>\n",
    "\n",
    "<p> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pediatric-spell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:59:45.277266700Z",
     "start_time": "2023-10-17T17:59:45.273759200Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, max_iter=1e4, lr=0.001, tol=0.001, print_every=100, batch_size=8192):\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.print_every = print_every\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        \n",
    "        self.check_regression_X_y(X_train, y_train)\n",
    "        self.check_regression_X_y(X_val, y_val)\n",
    "        \n",
    "        n, m = X_train.shape\n",
    "        \n",
    "        self.weights = np.ones((m, 1))\n",
    "        self.bias = y_train.mean()\n",
    "        \n",
    "        n_iter = 0\n",
    "        gradient_norm = np.inf\n",
    "        \n",
    "        while n_iter < self.max_iter and gradient_norm > self.tol:\n",
    "\n",
    "            indecies = np.random.randint(low=0, high=X_train.shape[0], size=self.batch_size)\n",
    "            dJdw, dJdb = self.grads(X_train[indecies], y_train[indecies])\n",
    "                \n",
    "            gradient_norm = np.linalg.norm(np.hstack([dJdw.flatten(), [dJdb]]))\n",
    "                \n",
    "            self.weights = self.weights - self.lr * dJdw\n",
    "            self.bias = self.bias - self.lr * dJdb\n",
    "            \n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter % self.print_every == 0:\n",
    "                self.print_metrics(X_train, y_train, X_val, y_val, n_iter, gradient_norm)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.weights + self.bias\n",
    "    \n",
    "    def grads(self, X, y):\n",
    "\n",
    "        y_hat = self.predict(X)\n",
    "        \n",
    "        dJdw = ((y_hat - y) * X).mean(axis=0, keepdims=True).T\n",
    "        dJdb = (y_hat - y).mean()\n",
    "\n",
    "        self.check_grads(dJdw, dJdb)\n",
    "        \n",
    "        return dJdw, dJdb\n",
    "    \n",
    "    def print_metrics(self, X_train, y_train, X_val, y_val, n_iter, gradient_norm):\n",
    "        \n",
    "        train_preds = self.predict(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "        \n",
    "        MAPE_train = get_mape(train_preds, y_train)\n",
    "        MAPE_val = get_mape(val_preds, y_val)\n",
    "        \n",
    "        print(f'{n_iter} completed. MAPE on train: {MAPE_train}, val: {MAPE_val},  grad norm: {gradient_norm}')\n",
    "        \n",
    "        \n",
    "    def check_grads(self, dJdw, dJdb):\n",
    "        \n",
    "        if not isinstance(dJdb, numbers.Real):\n",
    "            raise ValueError(f'Производная по параметру b должна быть действительным '\n",
    "                             f'числом, как и сам параметр b, а у нас {dJdb} типа {type(dJdb)}')\n",
    "            \n",
    "        if dJdw.shape != self.weights.shape:\n",
    "            raise ValueError(f'Размерность градиента по параметрам w должна совпадать с самим вектором w, '\n",
    "                             f'а у нас dJdw.shape = {dJdw.shape} не совпадает с weight.shape = {self.weights.shape}')\n",
    "            \n",
    "        \n",
    "    @staticmethod\n",
    "    def check_regression_X_y(X, y):\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            raise ValueError(f'X и y не должны быть пустыми, а у нас X.shape = {X.shape} и y.shape = {y.shape}')\n",
    "            \n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(f'X не должен содержать \"not a number\" (np.nan)')\n",
    "            \n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(f'y не должен содержать \"not a number\" (np.nan)')\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'Длина X и y должна быть одинаковой, а у нас X.shape = {X.shape}, y.shape = {y.shape}')\n",
    "            \n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(f'y - вектор ответов должен быть размерности (m, 1), а у нас y.shape = {y.shape}')\n",
    "                    \n",
    "        if np.any([(not isinstance(value, numbers.Real)) for value in y.flatten()]):\n",
    "            raise ValueError(f'Ответы на объектах должны быть действительными числами!')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-photographer",
   "metadata": {},
   "source": [
    "<h3>Тестируем модель на простой задаче</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "painted-cycle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:31:43.325174300Z",
     "start_time": "2023-10-17T17:31:43.171744700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 completed. MAPE on train: 0.05986845513923276, val: 0.05986845513923276,  grad norm: 0.04721174913987021\n",
      "200 completed. MAPE on train: 0.013152958287128286, val: 0.013152958287128286,  grad norm: 0.00997014189150913\n",
      "300 completed. MAPE on train: 0.0032241396452775497, val: 0.0032241396452775497,  grad norm: 0.002524994369805291\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1.00227301],\n       [2.00218537],\n       [3.00209773],\n       [3.99621483]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "y = np.array([[1], [2], [3], [4]])\n",
    "model = LinearRegression(lr=0.1)\n",
    "model.fit(X, y, X, y)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-longitude",
   "metadata": {},
   "source": [
    "<h3>Решаем задачу предсказания цены</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fleet-effort",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:33:17.769658200Z",
     "start_time": "2023-10-17T17:33:17.601492300Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('real_estate_novosibirsk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-chorus",
   "metadata": {},
   "source": [
    "<p>Чистим данные:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "korean-transition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:33:31.653948Z",
     "start_time": "2023-10-17T17:33:31.593766400Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=['item_id'], keep='last')\n",
    "data = data.dropna(subset=['area'])\n",
    "data['rooms_number'] = data['rooms_number'].apply(process_rooms_number).copy()\n",
    "data = data[(data.price > 970000) & (data.price < 12700000)]\n",
    "data = data[(data.floor < 59)]\n",
    "\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "disturbed-capitol",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:34:31.019977700Z",
     "start_time": "2023-10-17T17:34:31.007164400Z"
    }
   },
   "outputs": [],
   "source": [
    "train, val, train_price, val_price = train_test_split(data.drop('price', axis=1), data['price'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brutal-discretion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:34:58.034864Z",
     "start_time": "2023-10-17T17:34:58.025518800Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_price_estimator (2).csv')\n",
    "test, test_price = test_data.drop('price', axis=1), test_data['price']\n",
    "\n",
    "y_train = train_price.values.reshape(-1, 1)\n",
    "y_val = val_price.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-singer",
   "metadata": {},
   "source": [
    "### Делаем бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "entitled-copper",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:35:03.076591Z",
     "start_time": "2023-10-17T17:35:03.068166100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.37614684131639187"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mape(y_predict=np.median(y_train), y_true=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-blade",
   "metadata": {},
   "source": [
    "### Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-square",
   "metadata": {},
   "source": [
    "1) Начинаем с простого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "every-irish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:37:52.732942600Z",
     "start_time": "2023-10-17T17:37:26.989973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.32495804010076984, val: 0.31584565698364414,  grad norm: 176398.15897057083\n",
      "20000 completed. MAPE on train: 0.26970850832417564, val: 0.261715014421197,  grad norm: 58952.70546230126\n",
      "30000 completed. MAPE on train: 0.25501556254030644, val: 0.24728627123292868,  grad norm: 19702.14146001821\n",
      "40000 completed. MAPE on train: 0.2506691397472152, val: 0.24303110373999803,  grad norm: 6584.504902133548\n",
      "50000 completed. MAPE on train: 0.24928668407411153, val: 0.24167296738831417,  grad norm: 2200.5579898108713\n",
      "60000 completed. MAPE on train: 0.24883172794678735, val: 0.24122697532098183,  grad norm: 735.4319783332422\n",
      "70000 completed. MAPE on train: 0.24868115238629024, val: 0.24107995331682502,  grad norm: 245.78320465057666\n",
      "80000 completed. MAPE on train: 0.2486309578409756, val: 0.2410310124254577,  grad norm: 82.14136108844785\n",
      "90000 completed. MAPE on train: 0.24861418805052538, val: 0.241014662190146,  grad norm: 27.451848107767393\n",
      "100000 completed. MAPE on train: 0.24860858428470403, val: 0.24100919811964375,  grad norm: 9.174476226773193\n",
      "110000 completed. MAPE on train: 0.24860671149216526, val: 0.24100737201362968,  grad norm: 3.0661328773418353\n",
      "120000 completed. MAPE on train: 0.24860608560021974, val: 0.2410067617244373,  grad norm: 1.0247092683439272\n",
      "130000 completed. MAPE on train: 0.24860587642556772, val: 0.2410065577642644,  grad norm: 0.3424603977579973\n",
      "140000 completed. MAPE on train: 0.24860580651887645, val: 0.2410064896002651,  grad norm: 0.11445112054744473\n"
     ]
    },
    {
     "data": {
      "text/plain": "<__main__.LinearRegression at 0x1dd96a48690>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[['area']].values\n",
    "X_val = val[['area']].values\n",
    "\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=140000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-easter",
   "metadata": {},
   "source": [
    "<p>Для того, чтобы начать ориентироваться в метрике решения задачи, очень важно построить одну или несколько простых моделей. Часто есть соблазн добавить все признаки сразу и обучить модель — мы так поступать не будем. Наоборот, мы будем постепенно добавлять признаки и следить за тем, что модель решает задачу лучше и лучше. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-motorcycle",
   "metadata": {},
   "source": [
    "2) Увеличиваем количество признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hawaiian-swiss",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:38:24.019005400Z",
     "start_time": "2023-10-17T17:37:56.710069800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.34071672398641273, val: 0.33139777932922787,  grad norm: 202475.9417288229\n",
      "20000 completed. MAPE on train: 0.27783005179824266, val: 0.26892244418420735,  grad norm: 102561.201702077\n",
      "30000 completed. MAPE on train: 0.25360754966154325, val: 0.24497668881758333,  grad norm: 51950.863913807516\n",
      "40000 completed. MAPE on train: 0.24429354503583503, val: 0.2357741283603333,  grad norm: 26314.943824768892\n",
      "50000 completed. MAPE on train: 0.24051512736404806, val: 0.23220770453089087,  grad norm: 13329.446641150054\n",
      "60000 completed. MAPE on train: 0.23885963089488235, val: 0.2306786476480523,  grad norm: 6751.834582752558\n",
      "70000 completed. MAPE on train: 0.23809728785823325, val: 0.22998164981486588,  grad norm: 3420.0422163151065\n",
      "80000 completed. MAPE on train: 0.2377307046635948, val: 0.22965168927620386,  grad norm: 1732.3719380295931\n",
      "90000 completed. MAPE on train: 0.23754925343209923, val: 0.2294889857950511,  grad norm: 877.5074522049489\n",
      "100000 completed. MAPE on train: 0.23745898466190668, val: 0.22940771530799017,  grad norm: 444.4884564172299\n",
      "110000 completed. MAPE on train: 0.2374137295514664, val: 0.2293668963976285,  grad norm: 225.14907126061496\n",
      "120000 completed. MAPE on train: 0.23739095252589196, val: 0.22934642795296184,  grad norm: 114.04594103084295\n"
     ]
    },
    {
     "data": {
      "text/plain": "<__main__.LinearRegression at 0x1dd94a49c10>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[['area', 'floors_in_house', 'floor']].values\n",
    "X_val = val[['area', 'floors_in_house', 'floor']].values\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-telling",
   "metadata": {},
   "source": [
    "Делаем новые признаки\n",
    "##### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "developmental-shoot",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:39:46.125292300Z",
     "start_time": "2023-10-17T17:39:46.115102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  feature\n0       a\n1       b\n2       a\n3       c",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_example = pd.DataFrame({'feature': ['a', 'b', 'a', 'c']})\n",
    "ohe_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "remarkable-bedroom",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:39:52.671499400Z",
     "start_time": "2023-10-17T17:39:52.661501400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit_transform(ohe_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "moved-confusion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:44:09.199871600Z",
     "start_time": "2023-10-17T17:43:24.226923200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aleks\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.25853392474642173, val: 0.24946162482379938,  grad norm: 161356.2664430575\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m X_val_extended \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mhstack([X_val, val_ohe_house_type, val_ohe_district])\n\u001B[0;32m     12\u001B[0m model \u001B[38;5;241m=\u001B[39m LinearRegression(lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6e-4\u001B[39m, max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m120000\u001B[39m, print_every\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10000\u001B[39m, tol\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n\u001B[1;32m---> 13\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train_extended, y_train, X_val_extended, y_val)\n",
      "Cell \u001B[1;32mIn[6], line 29\u001B[0m, in \u001B[0;36mLinearRegression.fit\u001B[1;34m(self, X_train, y_train, X_val, y_val)\u001B[0m\n\u001B[0;32m     25\u001B[0m gradient_norm \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39minf\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m n_iter \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_iter \u001B[38;5;129;01mand\u001B[39;00m gradient_norm \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtol:\n\u001B[1;32m---> 29\u001B[0m     dJdw, dJdb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrads(X_train, y_train)\n\u001B[0;32m     31\u001B[0m     gradient_norm \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(np\u001B[38;5;241m.\u001B[39mhstack([dJdw\u001B[38;5;241m.\u001B[39mflatten(), [dJdb]]))\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr \u001B[38;5;241m*\u001B[39m dJdw\n",
      "Cell \u001B[1;32mIn[6], line 50\u001B[0m, in \u001B[0;36mLinearRegression.grads\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgrads\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y):\n\u001B[0;32m     48\u001B[0m     y_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(X)\n\u001B[1;32m---> 50\u001B[0m     dJdw \u001B[38;5;241m=\u001B[39m ((y_hat \u001B[38;5;241m-\u001B[39m y) \u001B[38;5;241m*\u001B[39m X)\u001B[38;5;241m.\u001B[39mmean(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m     51\u001B[0m     dJdb \u001B[38;5;241m=\u001B[39m (y_hat \u001B[38;5;241m-\u001B[39m y)\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_grads(dJdw, dJdb)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181\u001B[0m, in \u001B[0;36m_mean\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m    178\u001B[0m         dtype \u001B[38;5;241m=\u001B[39m mu\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf4\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    179\u001B[0m         is_float16_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 181\u001B[0m ret \u001B[38;5;241m=\u001B[39m umr_sum(arr, axis, dtype, out, keepdims, where\u001B[38;5;241m=\u001B[39mwhere)\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, mu\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _no_nep50_warning():\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ohe_house_type_transformer = OneHotEncoder(sparse=False)\n",
    "train_ohe_house_type = ohe_house_type_transformer.fit_transform(train[['type_of_house']])\n",
    "val_ohe_house_type = ohe_house_type_transformer.transform(val[['type_of_house']])\n",
    "\n",
    "ohe_district_transformer = OneHotEncoder(sparse=False)\n",
    "train_ohe_district = ohe_district_transformer.fit_transform(train[['district']])\n",
    "val_ohe_district = ohe_district_transformer.transform(val[['district']])\n",
    "\n",
    "X_train_extended = np.hstack([X_train, train_ohe_house_type, train_ohe_district])\n",
    "X_val_extended = np.hstack([X_val, val_ohe_house_type, val_ohe_district])\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train_extended, y_train, X_val_extended, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "turned-regulation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T18:03:35.019783100Z",
     "start_time": "2023-10-17T18:00:01.216447300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.34913096553477896, val: 0.33780964029429317,  grad norm: 35259039.05542406\n",
      "20000 completed. MAPE on train: 0.2135001930159604, val: 0.20619694615062906,  grad norm: 11239821.60750618\n",
      "30000 completed. MAPE on train: 0.2027799403839704, val: 0.19601508891327654,  grad norm: 11153157.372839529\n",
      "40000 completed. MAPE on train: 0.20137631969971675, val: 0.19403988577853978,  grad norm: 9404761.145880844\n",
      "50000 completed. MAPE on train: 0.22040161236665193, val: 0.21284251824393985,  grad norm: 9840230.077290695\n",
      "60000 completed. MAPE on train: 0.1929194530988486, val: 0.1857037856658644,  grad norm: 13820324.576880004\n",
      "70000 completed. MAPE on train: 0.36227675194042813, val: 0.3518530409200515,  grad norm: 53593580.198034845\n",
      "80000 completed. MAPE on train: 0.21698369669774392, val: 0.21123091262016894,  grad norm: 40097192.51639471\n",
      "90000 completed. MAPE on train: 0.20478118908796075, val: 0.19745486030538942,  grad norm: 11885837.567868296\n",
      "100000 completed. MAPE on train: 0.19975278685511272, val: 0.1924564615451875,  grad norm: 1784054.7775060094\n",
      "110000 completed. MAPE on train: 0.21111245025804345, val: 0.20359254769601678,  grad norm: 5099340.456397921\n",
      "120000 completed. MAPE on train: 0.1922426310221932, val: 0.18499267798698518,  grad norm: 10310036.306751927\n"
     ]
    },
    {
     "data": {
      "text/plain": "<__main__.LinearRegression at 0x1dd97546410>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1, batch_size=8196)\n",
    "model.fit(X_train_extended, y_train, X_val_extended, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-grammar",
   "metadata": {},
   "source": [
    "### Задание на семинаре: попробовать улучшить метрику MAPE до 15.8% (топ-1 без ML с первой недели).\n",
    "\n",
    "Варианты путей для улучшения:\n",
    "\n",
    "    1) Делать новые признаки из существующих;\n",
    "    2) Препроцессинг данных, целевой переменной - постпроцессинг ответов модели;\n",
    "    3) Анализ ошибок модели –> генерация идей;\n",
    "    4) Добавить регуляризацию;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-drink",
   "metadata": {},
   "source": [
    "<h3>Задание на семинаре: реализуем логистическую регрессию</h3>\n",
    "\n",
    "<p>Мы получаем оптимальные веса алгоритма градиентным спуском:</p>\n",
    "\n",
    "<p style=\"text-align:center\"><br />\n",
    "<br />\n",
    "<span class=\"math-tex\">\\(\\begin{bmatrix} w_{1}^{t+1}\\\\  ...\\\\ w_{m}^{t+1}\\\\  \\end{bmatrix} = \\begin{bmatrix} w_{1}^{t}\\\\  ...\\\\ w_{m}^{t}\\\\  \\end{bmatrix} - \\alpha \\cdot  \\begin{bmatrix} \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})x_{1}^{(i)}\\\\  ...\\\\ \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})x_{m}^{(i)}\\\\  \\end{bmatrix}\\)</span></p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(b^{t+1} = b^{t} - \\alpha \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})\\)</span></p>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, max_iter=1e4, lr=0.001, tol=0.001, print_every=100):\n",
    "        \n",
    "        '''\n",
    "        max_iter – максимальное количеств\n",
    "        '''\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        \n",
    "        '''\n",
    "        Обучение модели.\n",
    "        \n",
    "        X_train – матрица объектов для обучения\n",
    "        y_train – ответы на объектах для обучения\n",
    "        \n",
    "        X_val – матрица объектов для валидации\n",
    "        y_val – ответы на объектах для валидации\n",
    "        '''\n",
    "        \n",
    "        self.check_binary_clf_X_y(X_train, y_train)\n",
    "        self.check_binary_clf_X_y(X_val, y_val)\n",
    "                \n",
    "        n, m = X_train.shape\n",
    "        \n",
    "        self.weights = \n",
    "        self.bias = \n",
    "        \n",
    "        n_iter = 0\n",
    "        gradient_norm = np.inf\n",
    "        \n",
    "        while n_iter < self.max_iter and gradient_norm > self.tol:\n",
    "            \n",
    "            dJdw, dJdb = self.grads(X_train, y_train)\n",
    "            gradient_norm = np.linalg.norm(np.hstack([dJdw.flatten(), [dJdb]]))\n",
    "                \n",
    "            self.weights = \n",
    "            self.bias = \n",
    "            \n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter % self.print_every == 0:\n",
    "                self.print_metrics(X_train, y_train, X_val, y_val, n_iter, gradient_norm)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):  \n",
    "        \n",
    "        '''\n",
    "        Метод возвращает предсказанную метку класса на объектах X\n",
    "        '''\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        '''\n",
    "        Метод возвращает вероятность класса 1 на объектах X\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def grads(self, x, y):\n",
    "        \n",
    "        '''\n",
    "        Рассчёт градиентов\n",
    "        '''\n",
    "        y_hat = \n",
    "        \n",
    "        dJdw = \n",
    "        dJdb = \n",
    "        \n",
    "        self.check_grads(dJdw, dJdb)\n",
    "        \n",
    "        return dJdw, dJdb\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        '''\n",
    "        Сигмоида от x\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def print_metrics(self, X_train, y_train, X_val, y_val, n_iter, gradient_norm):\n",
    "        \n",
    "        train_preds = self.predict(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "        \n",
    "        train_acc = accuracy_score(train_preds, y_train)\n",
    "        val_acc = accuracy_score(val_preds, y_val)\n",
    "        \n",
    "        print(f'{n_iter} completed. accuracy_score on train: {train_acc}, val: {val_acc}, grad_norm: {gradient_norm}')\n",
    "        \n",
    "    def check_grads(self, dJdw, dJdb):\n",
    "        \n",
    "        if not isinstance(dJdb, numbers.Real):\n",
    "            raise ValueError(f'Производная по параметру b должна быть действительным'\n",
    "                             f' числом, как и сам параметр b, а у нас {dJdb} типа {type(dJdb)}')\n",
    "            \n",
    "        if dJdw.shape != self.weights.shape:\n",
    "            raise ValueError(f'Размерность градиента по параметрам w должна совпадать с самим вектором w, '\n",
    "                             f'а у нас dJdw.shape = {dJdw.shape} не совпадает с weight.shape = {self.weights.shape}')\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_binary_clf_X_y(X, y):\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            raise ValueError(f'X и y не должны быть пустыми, а у нас X.shape = {X.shape} и y.shape = {y.shape}')\n",
    "            \n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(f'X не должен содержать \"not a number\" (np.nan)')\n",
    "            \n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(f'y не должен содержать \"not a number\" (np.nan)')\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'Длина X и y должна быть одинаковой, а у нас X.shape = {X.shape}, y.shape = {y.shape}')\n",
    "            \n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(f'y - вектор ответов должен быть размерности (m, 1), а у нас y.shape = {y.shape}')\n",
    "\n",
    "                    \n",
    "        if sorted(np.unique(y)) != [0, 1]:\n",
    "            raise ValueError(f'Ответы на объектах должны быть только 0 или 1, а у нас np.unique(y) = {np.unique(y)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-cable",
   "metadata": {},
   "source": [
    "<h2>Домашнее задание</h2>\n",
    "\n",
    "<p>Воспользуемся реализованной моделью логистической регрессии, чтобы решить задачу определения пола пользователя Авито.</p>\n",
    "\n",
    "<p><a href=\"https://stepik.org/media/attachments/lesson/527992/binary_clf_data.csv\" rel=\"noopener noreferrer nofollow\">Данные</a> даны в сыром виде &ndash; айтемы и их категории, которые выкладывали покупатели на Авито. Целевая переменная: <em>gender.</em></p>\n",
    "\n",
    "<p>Вам необходимо разбить данные на train, val. Перед загрузкой файла с ответом убедитесь, что точность (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\" rel=\"noopener noreferrer nofollow\">accuracy</a>)&nbsp;на валидации не менее 0.7.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><strong>План действий</strong></p>\n",
    "\n",
    "<p>Сначала нужно преобразовать категории с помощью one-hot encoding. Далее необходимо агрегировать категории, в которых пользователи выкладывали объявления, чтобы получить вектор признаков для каждого объекта. В результате у каждого пользователя будет вектор признаков, содержащий количество айтемов, выложенных в каждой из возможных категорий.</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Убедитесь, что для каждого пользователя в выборке есть только один объект, каждый признак означает количество айтемов, выложенное этим пользователем в категории;</li>\n",
    "\t<li>Убедитесь, что после one-hot энкодинга каждая категория соответствует признаку,&nbsp;<strong>одинаковому в train, val и test.</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>Попробуйте варианты отбора признаков. Для борьбы с переобучением на редких категориях используйте регуляризацию. В качестве&nbsp;ответа загрузите файл с предсказанием пола для пользователей:</p>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<table align=\"center\" border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px\">\n",
    "\t<thead>\n",
    "\t\t<tr>\n",
    "\t\t\t<th style=\"text-align:center\">user_id</th>\n",
    "\t\t\t<th style=\"text-align:center\">gender</th>\n",
    "\t\t</tr>\n",
    "\t</thead>\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"text-align:center\">15424171</td>\n",
    "\t\t\t<td style=\"text-align:center\">male</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"text-align:center\">15454025</td>\n",
    "\t\t\t<td style=\"text-align:center\">female</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<p>Такой файл можно сформировать с помощью&nbsp;<code>test_predictions.to_csv(&#39;test_predictions.csv&#39;, index=False)</code>.</p>\n",
    "\n",
    "<p>После того, как получилось обучить модель, ответьте на вопрос: какие из категорий вносят наибольший вклад в вероятность класса &quot;мужчина&quot; и класса &quot;женщина&quot;?</p>\n",
    "\n",
    "<p>Например, если вы закодировали &quot;мужчина&quot; как 1, большие положительные веса при признаках будут означать большой вклад в вероятность класса 1, большие по модулю отрицательные веса будут вносить наибольший вклад в вероятность класса 0. Согласуется ли полученный результат с вашим жизненным опытом?</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
