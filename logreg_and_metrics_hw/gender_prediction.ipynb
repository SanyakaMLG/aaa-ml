{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numbers\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "\n",
    "    def __init__(self, max_iter=1e4, lr=0.002, beta=0.5, tol=0.001, print_every=100, l2_coef=0.5, l1_coef=0.1):\n",
    "\n",
    "        '''\n",
    "        max_iter – максимальное количеств\n",
    "        '''\n",
    "\n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.print_every = print_every\n",
    "        self.l2_coef = l2_coef\n",
    "        self.l1_coef = l1_coef\n",
    "        self.beta = beta\n",
    "\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "\n",
    "        '''\n",
    "        Обучение модели.\n",
    "\n",
    "        X_train – матрица объектов для обучения\n",
    "        y_train – ответы на объектах для обучения\n",
    "\n",
    "        X_val – матрица объектов для валидации\n",
    "        y_val – ответы на объектах для валидации\n",
    "        '''\n",
    "\n",
    "        self.check_binary_clf_X_y(X_train, y_train)\n",
    "        self.check_binary_clf_X_y(X_val, y_val)\n",
    "\n",
    "        n, m = X_train.shape\n",
    "        # self.weights = np.random.random((m, 1)) * 2 - 1\n",
    "        self.weights = np.zeros((m, 1))\n",
    "        self.bias = np.mean(y_train)\n",
    "\n",
    "        v_w, v_b = 0, 0\n",
    "\n",
    "        n_iter = 0\n",
    "        gradient_norm = np.inf\n",
    "\n",
    "        while n_iter < self.max_iter and gradient_norm > self.tol:\n",
    "\n",
    "            dJdw, dJdb = self.grads(X_train, y_train)\n",
    "            gradient_norm = np.linalg.norm(np.hstack([dJdw.flatten(), [dJdb]]))\n",
    "\n",
    "            v_w = self.beta * v_w + (1 - self.beta) * dJdw\n",
    "            self.weights = self.weights - self.lr * v_w\n",
    "\n",
    "            v_b = self.beta * v_b + (1 - self.beta) * dJdb\n",
    "            self.bias = self.bias - self.lr * v_b\n",
    "\n",
    "            # self.weights = self.weights - self.lr * dJdw\n",
    "            # self.bias = self.bias - self.lr * dJdb\n",
    "\n",
    "            n_iter += 1\n",
    "\n",
    "            if n_iter % self.print_every == 0:\n",
    "                self.print_metrics(X_train, y_train, X_val, y_val, n_iter, gradient_norm)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        '''\n",
    "        Метод возвращает предсказанную метку класса на объектах X\n",
    "        '''\n",
    "\n",
    "        return self.predict_proba(X) > 0.5\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        '''\n",
    "        Метод возвращает вероятность класса 1 на объектах X\n",
    "        '''\n",
    "        return self.sigmoid(X @ self.weights + self.bias)\n",
    "\n",
    "    def grads(self, X, y):\n",
    "\n",
    "        '''\n",
    "        Рассчёт градиентов\n",
    "        '''\n",
    "        y_hat = self.predict_proba(X)\n",
    "\n",
    "        sign = self.weights / (np.abs(self.weights) + 1e-20)\n",
    "        dJdw = np.mean(X * (y_hat - y), axis=0, keepdims=True).T + self.l1_coef * sign + self.l2_coef * self.weights\n",
    "        dJdb = np.mean(y_hat - y)\n",
    "\n",
    "        self.check_grads(dJdw, dJdb)\n",
    "\n",
    "        return dJdw, dJdb\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        '''\n",
    "        Сигмоида от x\n",
    "        '''\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def print_metrics(self, X_train, y_train, X_val, y_val, n_iter, gradient_norm):\n",
    "\n",
    "        train_preds = self.predict(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "\n",
    "        train_acc = accuracy_score(train_preds, y_train)\n",
    "        val_acc = accuracy_score(val_preds, y_val)\n",
    "\n",
    "        print(f'{n_iter} completed. accuracy_score on train: {train_acc}, val: {val_acc}, grad_norm: {gradient_norm}')\n",
    "\n",
    "    def check_grads(self, dJdw, dJdb):\n",
    "\n",
    "        if not isinstance(dJdb, numbers.Real):\n",
    "            raise ValueError(f'Производная по параметру b должна быть действительным'\n",
    "                             f' числом, как и сам параметр b, а у нас {dJdb} типа {type(dJdb)}')\n",
    "\n",
    "        if dJdw.shape != self.weights.shape:\n",
    "            raise ValueError(f'Размерность градиента по параметрам w должна совпадать с самим вектором w, '\n",
    "                             f'а у нас dJdw.shape = {dJdw.shape} не совпадает с weight.shape = {self.weights.shape}')\n",
    "\n",
    "    @staticmethod\n",
    "    def check_binary_clf_X_y(X, y):\n",
    "\n",
    "        if X.shape[0] == 0:\n",
    "            raise ValueError(f'X и y не должны быть пустыми, а у нас X.shape = {X.shape} и y.shape = {y.shape}')\n",
    "\n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(f'X не должен содержать \"not a number\" (np.nan)')\n",
    "\n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(f'y не должен содержать \"not a number\" (np.nan)')\n",
    "\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'Длина X и y должна быть одинаковой, а у нас X.shape = {X.shape}, y.shape = {y.shape}')\n",
    "\n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(f'y - вектор ответов должен быть размерности (m, 1), а у нас y.shape = {y.shape}')\n",
    "\n",
    "\n",
    "        if sorted(np.unique(y)) != [0, 1]:\n",
    "            raise ValueError(f'Ответы на объектах должны быть только 0 или 1, а у нас np.unique(y) = {np.unique(y)}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('binary_clf_data.csv')\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def refactor_subcat_name(row):\n",
    "    if isinstance(row.param1, str) and ('муж' in row.param1.lower() or 'жен' in row.param1.lower()):\n",
    "        return row.param1\n",
    "    return row.subcategory_name\n",
    "\n",
    "def gender_to_num(row):\n",
    "    if row.gender == 'male':\n",
    "        return 1\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['subcategory_name'] = df.apply(refactor_subcat_name, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df['gender'] == 'female']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ohe = ohe.fit_transform(df[['subcategory_name']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_extended = pd.DataFrame(np.hstack([df, df_ohe]))\n",
    "gender = df_extended[[0, 1]].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_extended"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_extended = df_extended.drop(columns=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]).groupby(1).sum().reset_index().merge(gender, on=1).rename(columns={1: 'user_id', 0: 'gender'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, val, train_gender, val_gender = train_test_split(df_extended.drop(['user_id', 'gender'], axis=1), df_extended[['gender']], random_state=260401)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_gender['gender'] = train_gender.apply(gender_to_num, axis=1)\n",
    "val_gender['gender'] = val_gender.apply(gender_to_num, axis=1)\n",
    "train_gender"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = 0\n",
    "res = []\n",
    "\n",
    "for lr in [0.001, 0.002, 0.005]:\n",
    "    for beta in [0, 0.1, 0.15, 0.25]:\n",
    "        for l1_coef in [0, 0.001, 0.01, 0.1]:\n",
    "            for l2_coef in [0, 0.01, 0.1, 0.25]:\n",
    "                logistic_regression = LogisticRegression(max_iter=3e4, lr=lr, beta=beta, l1_coef=l1_coef, l2_coef=l2_coef, print_every=30000)\n",
    "\n",
    "                logistic_regression.fit(train_scaled, train_gender.values, val.values, val_gender.values)\n",
    "\n",
    "                if accuracy_score(logistic_regression.predict(val.values), val_gender.values) > score:\n",
    "                    res = [lr, beta, l1_coef, l2_coef]\n",
    "                    score = accuracy_score(logistic_regression.predict(val.values), val_gender.values)\n",
    "                    if score > 0.75:\n",
    "                        print(f'score = {score}, parameters: {res}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=1e5, tol=1e-6, lr=0.002, beta=0.15, l1_coef=0, l2_coef=0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logistic_regression.fit(train_scaled, train_gender.values, val.values, val_gender.values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = pd.read_csv('dataset_527992_9.txt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_ohe = ohe.transform(test[['category_name', 'subcategory_name']])\n",
    "test_extended = np.hstack([test, test_ohe])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_prepared = pd.DataFrame(test_extended).drop(columns=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).rename(columns={0: 'user_id'}).groupby('user_id').sum().reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_prepared.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction = logistic_regression.predict(test_prepared.values[:, 1:]).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction = np.where(prediction == 1, 'male', 'female')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_prepared = test_prepared.join(pd.DataFrame(prediction))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_prepared[['user_id', 0]].to_csv('test_predictions.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
